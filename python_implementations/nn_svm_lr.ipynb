{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from linear_classifiers import *\n",
    "from prec_recall import prec_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (622, 28)\n",
      "[[ 0.29015516  0.04924313 -0.74052367 ...  2.74526067 -0.2204016\n",
      "   0.16823274]\n",
      " [-1.61218737 -4.62014787 -0.28331816 ...  0.89152121 -0.31278271\n",
      "   0.26827516]\n",
      " [-4.28058383  1.42110001 -3.90822884 ... -1.14992267 -1.80988612\n",
      "   0.72305143]\n",
      " ...\n",
      " [ 1.23220629  0.26485221  0.42781704 ... -0.44599829  0.03289931\n",
      "   0.01365267]\n",
      " [ 1.20493424  3.23806951 -6.0103244  ...  0.05603474  0.49182782\n",
      "   0.34084669]\n",
      " [-0.32479146  1.08346101 -1.20520689 ...  0.07256116  0.48961806\n",
      "   0.33803559]]\n",
      "[ 0.29015516  0.04924313 -0.74052367  2.86546277  1.39529392 -0.53516328\n",
      "  0.14254337 -0.22276971 -1.46369065  1.71353755 -1.12757349 -0.70865735\n",
      "  0.27218608  0.27471029  0.23519195 -0.46355271  0.47299539 -0.44789916\n",
      "  1.79092415  0.24757953  0.33734885  1.01819058  0.30355001  0.83388612\n",
      " -1.2223061   2.74526067 -0.2204016   0.16823274]\n"
     ]
    }
   ],
   "source": [
    "dataset = \"subsample\"\n",
    "\n",
    "if dataset == \"subsample\":\n",
    "    X_train = np.load(\"../data/subsamp_data/processed_X_train.npy\")\n",
    "    y_train = np.load(\"../data/subsamp_data/processed_y_train.npy\")\n",
    "elif dataset == \"origin\":\n",
    "    X_train = np.load(\"../data/origin_data/X_train.npy\")\n",
    "    y_train = np.load(\"../data/origin_data/y_train.npy\")\n",
    "else:\n",
    "    raise Exception(\"Unknown dataset name\")\n",
    "\n",
    "# val / test always on the largest dataset\n",
    "X_val = np.load(\"../data/origin_data/X_val.npy\")\n",
    "y_val = np.load(\"../data/origin_data/y_val.npy\")\n",
    "X_test = np.load(\"../data/origin_data/X_test.npy\")\n",
    "y_test = np.load(\"../data/origin_data/y_test.npy\")\n",
    "\n",
    "print(\"shape: {}\".format(X_train.shape))\n",
    "print(X_train)\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/wenqi/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from prec_recall import prec_recall\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 12)\n",
      "(12, 6)\n",
      "(6, 1)\n",
      "[[ 0.5135794   1.1593744  -0.08030141  0.2788803  -0.10667941 -0.91568094\n",
      "  -0.9699817   2.1473632  -0.65720606 -0.97112805  2.1592956  -0.23425752]\n",
      " [ 0.513026   -0.86688733  0.14152195  0.9756269  -0.03812868  0.16613284\n",
      "   0.6390418  -1.0894452   0.23098922 -0.43166974  0.195443    0.27169588]\n",
      " [-0.79612184 -0.31300616  0.01003939  0.5441564   0.6771815   0.86358047\n",
      "   0.46836215 -0.0691051  -0.75780225 -0.21152873 -0.05263001  0.15522678]\n",
      " [-1.9530405  -0.98751664  0.07709956 -0.4244684   0.33330667 -0.28903294\n",
      "  -1.3645107   0.32463753  1.6065955   0.4968592  -0.87009495  0.44481802]\n",
      " [ 2.5732617  -0.28998384 -0.17923625 -0.0110664  -0.8278394   0.35161057\n",
      "   0.86983216 -0.9587814   0.19139259 -0.07849523 -0.19551651 -0.30567694]\n",
      " [-0.03341743 -0.45875236 -0.33527657  0.7639824   0.0118873   0.753918\n",
      "  -0.2722627   0.48212224 -0.09232956 -0.7805643  -0.77936244  0.7769905 ]\n",
      " [ 1.1727765  -0.04304819  0.03146831 -0.43923208  0.28405398  0.17397723\n",
      "   0.51668304 -0.8976285  -0.14644285  0.19488886  0.7296527   0.12374379]\n",
      " [-0.66454196 -1.1533505  -0.00436943  1.5010909   2.29928    -0.03474662\n",
      "   1.1396257   0.13890123 -0.85443574 -0.14345811 -1.3259217   0.2710938 ]\n",
      " [ 0.20103626 -0.32060528 -0.18836904  0.28001404 -0.11233502 -0.42424387\n",
      "  -0.00511877  0.65906036 -0.90546644  0.5316112  -0.01818904  0.28244597]\n",
      " [-1.3814654   0.3714376   0.48006535  0.89515555  0.4212374   0.06692991\n",
      "   0.16145284  0.2722626   0.18000817 -0.600163    0.21003164  0.4510544 ]\n",
      " [ 0.38974565  1.2915497  -0.30204123  0.32883912 -0.4915615  -1.2208613\n",
      "  -0.08768336 -0.04618805  0.8865553   0.80042696  0.3497296  -1.1470836 ]\n",
      " [ 0.5978662   0.10129674  0.4727694   0.35101867  1.029671   -0.27676967\n",
      "   0.27351326  0.242558   -1.6906922  -0.39627808 -0.2056963   0.6193401 ]\n",
      " [ 0.29749247  0.78276515  0.42301404 -0.05685955  0.06479193 -0.45018557\n",
      "  -0.10396905 -0.27446708 -0.3927667  -0.20270313 -0.30217123 -0.64714605]\n",
      " [-0.41512972  0.7330446  -0.62619305  0.8337254   0.4736911   0.45116693\n",
      "   0.8758938   0.656156   -1.3725021  -0.62152946  0.84071183  0.82424027]\n",
      " [ 0.31877887 -0.18900698  0.19107024  0.73367715 -0.29247892 -0.5169659\n",
      "  -0.4962478   0.5494197  -0.5003253   0.17983362  0.7062216  -0.4479145 ]\n",
      " [ 0.5818656   0.6753052   0.65413237 -0.7051113   0.41106528  0.5042236\n",
      "   0.312612   -0.3689969   0.1376987  -0.64615023 -0.5285296   0.7189571 ]\n",
      " [-0.308465    0.20790835  0.37539193  0.31671476  0.18167494 -0.23514417\n",
      "   0.39871308  0.1752029   0.1949047  -0.16096944  0.5998705   0.40646967]\n",
      " [ 0.40092856  0.5490123   0.51579666  0.39013174 -0.3374663  -0.0775245\n",
      "  -0.02237423 -0.95333546 -0.30713722  0.5026935  -1.3377744  -0.68549204]\n",
      " [-0.68949986 -0.27032822  0.9656887  -0.26304436  0.26557428  0.29631588\n",
      "   0.3395249  -0.792522   -0.34309208  0.01508362 -0.35478857  0.07754801]\n",
      " [-0.2227263   0.01699541 -0.30243662 -0.6811456  -0.32858127  0.7601881\n",
      "  -0.2831707   0.16546091 -0.7247613   0.01042707 -0.19804758  0.06953064]\n",
      " [ 0.3937629   0.25978222 -0.42514026 -0.12705173 -0.2780822  -0.27970213\n",
      "  -0.25784513 -0.1648046   0.38929653  1.0053283  -0.00591952 -0.12509099]\n",
      " [ 0.7038696   0.41183445  0.02443839  0.0423009   0.03018351 -0.97559935\n",
      "   0.24184076 -0.04491607 -0.1584906  -0.23568931 -0.20193899  0.14790584]\n",
      " [ 0.6672816   0.27798003 -0.33972448  0.41543517 -0.11546936 -0.12126278\n",
      "   0.2556801   0.25248176 -0.21778801 -0.13913634  0.44396853  0.6946661 ]\n",
      " [-0.26786047  0.13615404  0.06995953 -0.06236096  0.5468289   0.14251283\n",
      "  -0.46093464  0.5633534  -0.32886863 -0.05096725  0.30871904 -0.38670874]\n",
      " [-0.7086423  -0.03215452  0.57737166 -0.8056575  -1.2954993  -0.07289566\n",
      "  -0.3704829   0.4150837  -0.02171499 -0.40276885  0.27675825  0.29049444]\n",
      " [ 0.8159612   0.25358808  0.17633829  0.08794904  0.11696852 -0.13284121\n",
      "   0.5524527   0.2655669  -0.69695026 -0.85024494  1.0685645  -0.13977212]\n",
      " [-0.32090536  0.55106103  0.46803543  0.06997222 -0.10423491  0.32933092\n",
      "  -1.0564324  -0.5836581   0.161211    0.21534488 -0.45291793  0.2889531 ]\n",
      " [-1.1005096  -0.46374264  0.9275139   0.8246376   0.66824204 -0.40823454\n",
      "  -1.1746873   0.03984924  0.7345154   0.9154484  -1.1946417  -0.3944439 ]]\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "biases = []\n",
    "\n",
    "for i in range(1, 4):\n",
    "    weights.append(np.load(\"../keras/models_best/w_{}.npy\".format(i)))\n",
    "    biases.append(np.load(\"../keras/models_best/b_{}.npy\".format(i)))\n",
    "    \n",
    "for w in weights:\n",
    "    print(w.shape)\n",
    "    \n",
    "print(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:\t0.05856779099999976\n",
      "result:\t[[1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "TP count:    91\n",
      "FP count:    8936\n",
      "TN count:    47932\n",
      "FN count:    3\n",
      "Precision rate:  0.010080868505594328\n",
      "Recall rate: 0.9680851063829787\n",
      "Accuracy：0.8430708191425863\n",
      "TP count:    82\n",
      "FP count:    8785\n",
      "TN count:    48090\n",
      "FN count:    5\n",
      "Precision rate:  0.009247772640126311\n",
      "Recall rate: 0.9425287356321839\n",
      "Accuracy：0.8456865980829325\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "my_pred = neural_networks(X_val, weights, biases)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(\"time:\\t{}\\nresult:\\t{}\".format(end - start, my_pred[0:10]))\n",
    "# print(my_pred)\n",
    "prec_recall(y_val, my_pred)\n",
    "my_pred = neural_networks(X_test, weights, biases)\n",
    "prec_recall(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:\t0.0014024279999986788\n",
      "result:\t[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "TP count:    76\n",
      "FP count:    29\n",
      "TN count:    56839\n",
      "FN count:    18\n",
      "Precision rate:  0.7238095238095238\n",
      "Recall rate: 0.8085106382978723\n",
      "Accuracy：0.9991748885221726\n",
      "TP count:    65\n",
      "FP count:    24\n",
      "TN count:    56851\n",
      "FN count:    22\n",
      "Precision rate:  0.7303370786516854\n",
      "Recall rate: 0.7471264367816092\n",
      "Accuracy：0.9991924440855307\n"
     ]
    }
   ],
   "source": [
    "w = np.load(\"../sklearn/model_LR/LR_best/w.npy\")\n",
    "b = np.load(\"../sklearn/model_LR/LR_best/b.npy\")\n",
    "\n",
    "start = time.perf_counter()\n",
    "my_pred = logistic_regression(X_val, w, b)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(\"time:\\t{}\\nresult:\\t{}\".format(end - start, my_pred[0:10]))\n",
    "prec_recall(y_val, my_pred)\n",
    "my_pred = logistic_regression(X_test, w, b)\n",
    "prec_recall(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "TP count:    74\n",
      "FP count:    22\n",
      "TN count:    56846\n",
      "FN count:    20\n",
      "Precision rate:  0.7708333333333334\n",
      "Recall rate: 0.7872340425531915\n",
      "Accuracy：0.9992626663389628\n",
      "TP count:    65\n",
      "FP count:    17\n",
      "TN count:    56858\n",
      "FN count:    22\n",
      "Precision rate:  0.7926829268292683\n",
      "Recall rate: 0.7471264367816092\n",
      "Accuracy：0.9993153330290369\n"
     ]
    }
   ],
   "source": [
    "w = np.load(\"../sklearn/model_SVM/SVM_best/w.npy\")\n",
    "b = np.load(\"../sklearn/model_SVM/SVM_best/b.npy\")\n",
    "\n",
    "my_pred = logistic_regression(X_val, w, b)\n",
    "print(my_pred[0:10])\n",
    "prec_recall(y_val, my_pred)\n",
    "my_pred = logistic_regression(X_test, w, b)\n",
    "prec_recall(y_test, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
